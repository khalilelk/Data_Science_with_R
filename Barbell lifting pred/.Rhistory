mtcars2$carb <- factor(mtcars$2carb)
mtcars2$am <- factor(mtcars2$am,labels=c('Automatic','Manual'))
str(mtcars2)
mtcars2$carb <- factor(mtcars2$2carb)
mtcars2$carb <- factor(mtcars2$carb)
str(mtcars2)
install.packages("GGally")
install.packages("GGally")
library(GGally)
install.packages("GGally")
library(GGally)
?ggpairs
ggpairs(mtcars2,columns = 1:11,title = "Pairs")
ggpairs(mtcars,columns = 1:11,title = "Pairs")
?ggpairs
ggpairs(mtcars, mapping = NULL, columns = 1:11, title = "Pairs plot",upper = list(continuous = "points", combo = "facethist", discrete ="facetbar", na = "na"), lower = list(continuous = "points", combo = "facethist", discrete ="facetbar", na = "na")
ggpairs(mtcars, columns = 1:4,upper = list(continuous="points",combo="facethist",discrete="facetbar",na="na"),lower= list(continuous="points",combo="facethist",discrete="facetbar",na="na"))
ggpairs(mtcars, columns = 1:4,title = "pairs plot for mtcars data set" upper = list(continuous="smooth_loess",combo="facethist",discrete="facetbar",na="na"),lower= list(continuous="points",combo="facethist",discrete="facetbar",na="na"))
ggpairs(mtcars, columns = 1:4,title = "pairs plot for mtcars data set" ,upper = list(continuous="smooth_loess",combo="facethist",discrete="facetbar",na="na"),lower= list(continuous="points",combo="facethist",discrete="facetbar",na="na"))
ggpairs(mtcars, columns = 1:11,title = "pairs plot for mtcars data set" ,upper = list(continuous="smooth_loess",combo="facethist",discrete="facetbar",na="na"),lower= list(continuous="points",combo="facethist",discrete="facetbar",na="na"))
ggpairs(mtcars2, columns = 1:5,title = "pairs plot for mtcars data set" ,upper = list(continuous="smooth_loess",combo="facethist",discrete="facetbar",na="na"),lower= list(continuous="points",combo="facethist",discrete="facetbar",na="na"))
?mtcars
library(ggplot2)
plot2 <- ggplot(data = mtcars2,aes(am,mpg))
plot2 + geom_boxplot()
plot2 + geom_boxplot(aes(fill=am))
?ggplot
plot2 + geom_boxplot(aes(fill=am,xlab("Transmission type"),ylab("Fuel consumption (Miles/gallon")))
plot2 + geom_boxplot(aes(fill=am,xlab("Transmission type"),ylab("Fuel consumption (Miles/gallon)")))
plot2 + geom_boxplot(aes(fill=am),xlab("Transmission type"),ylab("Fuel consumption (Miles/gallon)"))
plot2 + geom_boxplot(aes(fill=am))+labs(x="Transmission type",y="Fuel consumption")
?aes
plot2 + geom_boxplot(aes(fill=am))+labs(x="Transmission type",y="Fuel consumption")+geom_text(stat = "mean")
plot2 + geom_boxplot(aes(fill=am))+labs(x="Transmission type",y="Fuel consumption")+stat_sum()
?stat_boxplot
plot2 + geom_boxplot(aes(fill=am))+labs(x="Transmission type",y="Fuel consumption")+stat_boxplot()
plot2 + geom_boxplot(aes(fill=am))+labs(x="Transmission type",y="Fuel consumption")+stat_quantile()
?stat_bin
?geom_boxplot
draft_model <- lm(mpg ~ ., data = mtcars)
fitted-model <- step(draft-model, direction = "both")
draft-model <- lm(mpg ~ ., data = mtcars)
fitted-model <- step(draft-model, direction = "both")
draft-model <- lm(mpg ~ ., data = mtcars)
draft_model <- lm(mpg ~ ., data = mtcars)
fitted_model <- step(draft_model,direction = "both")
summary(fitted_model)
draft_model <- lm(mpg ~ ., data = mtcars2)
fitted_model <- step(draft_model,direction="both")
summary(fitted_model)
basic_model <- lm(mpg ~ am, data = mtcars2)
anova(basic_model, fitted_model)
?mfrow
?par
library(graphics)
par(mfrow=c(2,2))
plot(fitted_model)
?hatvalues
influence.measures(fitted_model)
leverage <- hatvalues(fitted_model)
tail(sort(leverage),3)
Influential <- dfbetas(fitted_model)
Influential
leverage
Influential <- dfbetas(fitted_model)
tail(sort(Influential[,6]),3)
t.test(mpg~am, data = mtcars2)
---
library(GGally)
ggpairs(mtcars2, columns = c(1:6,8,9),title = "pairs plot for mtcars data set" ,upper = list(continuous="smooth_loess",combo="facethist",discrete="facetbar",na="na"),lower= list(continuous="points",combo="facethist",discrete="facetbar",na="na"))
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
data(AlzheimerDisease)
?createdatapartition
?createDataPartition
?AlzheimerDisease
data(AlzheimerDisease)
summary(predictors)
str(predictors)
?predictors
?diagnosis
library(caret)
?createDataPartition
require(caret)
?createDataPartition
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
install.packages(“caret”, dependencies = c(“Depends”, “Suggests”))
install.packages("caret",dependencies = c("Depends","Suggests"))
library(caret)
createDataPartition
?createDataPartition
require(caret)
sessionInfo()
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
install.packages("MASS")
# installing/loading the package:
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr
updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
sessionInfo()
clear()
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(caret)
install.packages("caret")
library(caret)
install.packages("pbkrtest")
library(caret)
install.packages("minqa")
library(caret)
install.packages("caret",dependencies = c("Depends","Suggests"))
library(caret)
install.packages("nloptr")
install.packages("caret",dependencies = c("Depends","Imports","Suggests"))
library(caret)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
str(training)
summary(testing)
?createDataPartition
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("Hmisc")
library(Hmisc)
?cut2
typeof(mixtures$CompressiveStrength)
mixtures$CompressiveStrength <- cut2(mixtures$CompressiveStrength)
str(mixtures$CompressiveStrength)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7,list = FALSE)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7,list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
cmodel <- train(Class ~ ., method = "rpart", data = training)
cmodel$finalModel
library(rpart.plot)
fancyRpartPlot(cmodel$finalModel)
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
install.packages("rattle")
library(rpart.plot)
?fancyRpartPlot
install.packages("rpart.plot")
install.packages("rpart.plot")
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(cmodel$finalModel)
fancyRpartPlot(cmodel$finalModel)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
cmodel <- train(Class ~ ., method = "rpart", data = training)
cmodel$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(cmodel$finalModel)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
cmodel <- train(Class ~ ., method = "rpart", data = training)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
cmodel <- train(Class ~ ., method = "rpart", data = training)
cmodel$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(cmodel$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
OliveMod <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata = as.data.frame(t(colMeans(olive)))
newdata = as.data.frame(t(colMeans(olive)))
predict(OliveMod,data=newdata)
predict(OliveMod,data=newdata)
newdata = as.data.frame(t(colMeans(olive)))
newdata = as.data.frame(t(colMeans(olive)))
predict(OliveMod,newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
source('D:/Courses/Data science Specialization/C8 - Machine learning/quiz3/quiz3.R')
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(trainSA$chd,predict(modelSA,newdata = trainSA))
missClass(trainSA$chd,predict(modelSA,newdata = trainSA))
missClass(testSA$chd,predict(modelSA,newdata = testSA))
missClass(testSA$chd,predict(modelSA,newdata = testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
source('D:/Courses/Data science Specialization/C8 - Machine learning/quiz3/quiz3.R')
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
install.packages("elasticnet")
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate)  # For year() function below
dat = read.csv("/Users/cheyu/Documents/MOOC/MachineLearning/gaData.csv")
training = dat[year(dat$date) < 2012, ]
testing = dat[(year(dat$date)) > 2011, ]
tstrain = ts(training$visitsTumblr)
dat = read.csv("D:\RWSPACE/gaData.csv")
training = dat[year(dat$date) < 2012, ]
testing = dat[(year(dat$date)) > 2011, ]
tstrain = ts(training$visitsTumblr)
dat = read.csv("D:/RWSPACE/gaData.csv")
training = dat[year(dat$date) < 2012, ]
testing = dat[(year(dat$date)) > 2011, ]
tstrain = ts(training$visitsTumblr)
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
install.packages("forecast")
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
install.packages("e1071")
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
rm(list = ls())
setwd("D:/RWSPACE/pml-proj")
training <- read.csv("pml-training.csv", na.strings = c("NA", ""))
testing <- read.csv("pml-testing.csv", na.strings = c("NA", ""))
dim(training);dim(testing)
colnames(testing)
head(testing$X)
head(testing$raw_timestamp_part_1)
dim(testing)[,2]
dim(testing)[[,2]]
dim(testing)[2]
traindata <- traindata[,8:dim(traindata)[2]]
traindata <- training
testdata <- testing
traindata <- traindata[,8:dim(traindata)[2]]
testdata <- testdata[,8:dim(testdata)[2]]
dim(traindata)
dim(testdata)
var <- c(1,3,5,7)
var[2]
length(traindata)
sum(is.na(traindata[,1]))
sum(is.na(traindata[,2]))
sum(is.na(traindata[,3]))
?is.na
sumNA <- c()
for(i in 1:length(traindata)){
sumNA[i] <- sum(is.na(traindata[,i]))
}
sumNA
traindata[,5]
var <- c(1,2,8,7,,8.55,-7,-9)
var <- c(1,2,8,7,"",8.55,-7,-9)
is.na(var)
sum(is.na(var))
var <- c(1,2,8,7,"NA",8.55,-7,-9)
is.na(var)
var <- c(1,2,8,7,/*/574,8.55,-7,-9)
var <- c(1,2,8,7,?,8.55,-7,-9)
is.na(?)
is.na(*)
is.na(5)
is.na(*)
is.na(NA)
var <- c(1,2,8,7,na,8.55,-7,-9)
var <- c(1,2,8,7,na,8.55,-7,-9)
var <- c(1,2,8,7,NA,8.55,-7,-9)
is.na(NA)
is.na(var)
sum(is.na(var))
sumNA
colNA <- c()
legnth(sumNA)
leNGth(sumNA)
length(sumNA)
cut <- 0.7*dim(traindata)[1])
cut <- 0.7*dim(traindata)[1]
cut
colNA <- c()
cut <- 0.7*dim(traindata)[1]
for(i in length(sumNA)){
j <- 1
if(sumNA[i] > cut) {colNA[j] <- i}
j <- j+1
}
colNA
colNA <- c()
cut <- 0.7*dim(traindata)[1]
j <- 1
for(i in length(sumNA)){
if(sumNA[i] > cut) {colNA[j] <- i}
j <- j+1
}
colNA
colNA <- c()
cut <- 0.7*dim(traindata)[1]
j <- 1
for(i in length(sumNA)){
if(sumNA[i] > cut) {
colNA[j] <- i
j <- j+1
}
}
colNA
colNA <- c()
cut <- 0.7*dim(traindata)[1]
j <- 1
for(i in length(sumNA)){
if(sumNA[i] > cut) {
colNA[j] <- i
j <- j+1
}
else {j <- j+1}
}
colNA
colNA <- c()
cut <- 0.7*dim(traindata)[1]
j <- 1
for(i in 1:length(sumNA)){
if(sumNA[i] > cut) {
colNA[j] <- i
j <- j+1
}
else {j <- j+1}
}
colNA
colNA <- c()
cut <- 0.7*dim(traindata)[1]
j <- 1
for(i in 1:length(sumNA)){
if(sumNA[i] > cut) {
colNA[j] <- i
j <- j+1
}
}
colNA
colNA <- c()
cut <- 0.7*dim(traindata)[1]
j <- 1
for(i in 1:length(sumNA)){
if(sumNA[i] > cut)
colNA[j] <- i
j <- j+1
}
colNA <- c()
cut <- 0.7*dim(traindata)[1]
j <- 1
for(i in 1:length(sumNA)){
if(sumNA[i] > cut){
colNA[j] <- i
j <- j+1
}
}
traindata <- traindata[,-colNA]
library(caret)
newset <- nearZeroVar(traindata,saveMetrics = TRUE)
colnames(newset)
colnames(traindata)
summary(newset)
str(newset)
sum(is.na(testdata$total_accel_belt))
testdata <- testdata[,-colNA]
dim(testdata)
dim(traindata)
inTrain <- createDataPartition(traindata$classe,p=0.6,list = FALSE)
mytraining <- traindata[inTrain,]
mytesting <- traindata[-inTrain,]
dim(mytraining);dim(mytesting)
myTrain <- traindata[inTrain,]
myValid <- traindata[-inTrain,]
dim(myTrain);dim(myValid)
control <- trainControl(method = "cv", number = 5)
rpart_mod <- train(classe ~ ., data = myTrain, method = "rpart",
trControl = control)
print(rpart_mod, digits = 4)
fancyRpartPlot(rpart_mod$finalModel)
library(caret); library(rattle); library(rpart); library(rpart.plot)
library(randomForest); library(repmis)
install.packages("repmis")
fancyRpartPlot(rpart_mod$finalModel)
# prediction using validation dataset
predict1 <- predict(rpart_mod, myValid)
# Results
ConfMatrix <- confusionMatrix(myValid$classe, predict1)
ConfMatrix
ConfMatrix$overall[1]
RF_mod <- train(classe ~ ., data = myTrain, method = "rf",
trControl = control)
print(RF_mod, digits = 4)
# prediction using validation dataset
predict2 <- predict(RF_mod, myValid)
# Results
ConMatrix_RF <- confusionMatrix(myValid$classe, predict2)
ConfMatrix_RF <- confusionMatrix(myValid$classe, predict2)
ConfMatrix_RF$overall[1]
predict(RF_mod,testdata)
installed.packages("shiny")
install.packages("shiny")
rm(ls=list())
